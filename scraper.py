import os
import time
import re
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# å®Ÿè¡Œé–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
start_time = time.time()

# æœ€å¤§å®Ÿè¡Œæ™‚é–“ï¼ˆç§’å˜ä½ï¼‰6æ™‚é–“ã‚ˆã‚Šå°‘ã—çŸ­ãï¼ˆ5æ™‚é–“ã§ä¿å­˜ï¼‰
# è©¦é¨“çš„ã«çŸ­ã‚ã«è¨­å®š
MAX_EXECUTION_TIME = 1 * 20 * 60  # 10åˆ†

def init_driver():
    """ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹Chromeã®ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’åˆæœŸåŒ–"""
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    driver.set_page_load_timeout(600)
    return driver

def get_search_url(page_number):
    return f"https://tabelog.com/rstLst/{page_number}/?Srt=D&SrtT=nod"

def scrape_search_page(driver, page_number):
    """æ¤œç´¢ãƒšãƒ¼ã‚¸ã‹ã‚‰å€‹åˆ¥ãƒšãƒ¼ã‚¸ã®URLã‚’å–å¾—"""
    url = get_search_url(page_number)
    print(f"ã€æ¤œç´¢ãƒšãƒ¼ã‚¸å–å¾—ã€‘{url}")
    try:
        driver.get(url)
        time.sleep(10)  # é©åˆ‡ãªå¾…æ©Ÿæ™‚é–“
        elements = driver.find_elements(By.CSS_SELECTOR, 'div.list-rst.js-bookmark.js-rst-cassette-wrap.js-done')
        return [el.get_attribute("data-detail-url") for el in elements if el.get_attribute("data-detail-url")]
    except Exception as e:
        print(f"æ¤œç´¢ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {url} - {e}")
        return []

def extract_phone_number(text):
    """ãƒ†ã‚­ã‚¹ãƒˆå†…ã‹ã‚‰æœ€åˆã«è¦‹ã¤ã‹ã£ãŸé›»è©±ç•ªå·ã‚’æŠ½å‡º"""
    phone_pattern = re.compile(r'\d{2,4}-\d{2,4}-\d{4}')  # ä¾‹: 03-1234-5678, 0120-12-3456
    match = phone_pattern.search(text)
    return match.group(0) if match else "Not Found"

def scrape_detail_page_with_retry(url, max_retries=15):
    """å€‹åˆ¥ãƒšãƒ¼ã‚¸ã‹ã‚‰æƒ…å ±ã‚’å–å¾—ï¼ˆæœ€å¤§15å›ãƒªãƒˆãƒ©ã‚¤ï¼‰"""
    for attempt in range(max_retries):
        driver = None
        try:
            print(f"ã€å€‹åˆ¥ãƒšãƒ¼ã‚¸å–å¾—ã€‘{url} (Attempt {attempt+1})")
            driver = init_driver()
            driver.get(url)
            time.sleep(10)  # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å¾…æ©Ÿ

            record = {'URL': url, 'åº—å': '', 'é›»è©±ç•ªå·': ''}

            # ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ï¼ˆåº—åã¨ã—ã¦ä½¿ç”¨ï¼‰
            record['åº—å'] = driver.title.strip()
            
            # ãƒšãƒ¼ã‚¸ã®HTMLå…¨ä½“ã‚’å–å¾—ï¼ˆã‚¿ã‚°å«ã‚€ï¼‰
            page_html = driver.page_source
            print("ğŸ“„ ãƒšãƒ¼ã‚¸ã®HTMLï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰:")
            print(page_html)
            print("=" * 100)  # åŒºåˆ‡ã‚Šç·š

            # ãƒšãƒ¼ã‚¸ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ï¼ˆã‚¿ã‚°ã‚’é™¤ã„ãŸç´”ç²‹ãªãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã®ã¿ï¼‰
            page_text = driver.find_element(By.TAG_NAME, "body").text
            print("ğŸ” ãƒšãƒ¼ã‚¸å…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰:")
            print(page_text)
            print("-" * 80)  # åŒºåˆ‡ã‚Šç·š

            # æ­£è¦è¡¨ç¾ã§æœ€åˆã®é›»è©±ç•ªå·ã‚’æŠ½å‡º
            record['é›»è©±ç•ªå·'] = extract_phone_number(page_text)

            # å–å¾—ã—ãŸæƒ…å ±ã‚’é€ä¸€print
            print(f"URL: {record['URL']}")
            print(f"åº—å: {record['åº—å']}")
            print(f"é›»è©±ç•ªå·: {record['é›»è©±ç•ªå·']}")
            print("-" * 40)

            driver.quit()
            return record
        except Exception as e:
            print(f"Error processing {url} on attempt {attempt+1}: {e}")
            if driver:
                driver.quit()
            if attempt == max_retries - 1:
                print(f"Max retries reached for {url}, skipping.")
                return None
            time.sleep(10)  # ãƒªãƒˆãƒ©ã‚¤å‰ã«å°‘ã—å¾…æ©Ÿ
    return None

def load_previous_data(filename):
    """ä»¥å‰ã®CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºã®DataFrameã‚’è¿”ã™ï¼‰"""
    if os.path.exists(filename):
        return pd.read_csv(filename)
    return pd.DataFrame()

def compare_and_mark(new_df, old_df):
    """URLã‚’ã‚­ãƒ¼ã«å‰å›ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒã—ã€æ–°è¦ãƒ»æ›´æ–°ã‚’ãƒãƒ¼ã‚¯"""
    new_df['Status'] = ''
    if old_df.empty:
        new_df['Status'] = 'New'
    else:
        for idx, row in new_df.iterrows():
            url = row['URL']
            if url in old_df['URL'].values:
                old_row = old_df[old_df['URL'] == url].iloc[0]
                if row['åº—å'] != old_row['åº—å'] or row['é›»è©±ç•ªå·'] != old_row['é›»è©±ç•ªå·']:
                    new_df.at[idx, 'Status'] = 'Update'
            else:
                new_df.at[idx, 'Status'] = 'New'
    return new_df

def save_data(data, partial=False):
    """ãƒ‡ãƒ¼ã‚¿ã‚’CSVã¨ã—ã¦ä¿å­˜"""
    df = pd.DataFrame(data)
    filename = "data_partial.csv" if partial else "data.csv"
    df.to_csv(filename, index=False, encoding="utf-8-sig")
    print(f"âœ… {filename} ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆ{len(df)}ä»¶ï¼‰")

def main():
    all_records = []
    try:
        for page in range(1, 61):
            # 5æ™‚é–“çµŒéæ™‚ç‚¹ã§å¼·åˆ¶ä¿å­˜
            elapsed_time = time.time() - start_time
            if elapsed_time > MAX_EXECUTION_TIME:
                print("âš ï¸ 5æ™‚é–“çµŒéï¼é€”ä¸­ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¦çµ‚äº†ã—ã¾ã™ã€‚")
                save_data(all_records, partial=True)
                return  

            search_driver = init_driver()
            detail_urls = scrape_search_page(search_driver, page)
            search_driver.quit()

            for detail_url in detail_urls:
                record = scrape_detail_page_with_retry(detail_url, max_retries=5)
                if record:
                    all_records.append(record)
    except Exception as e:
        print("äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:", e)
    finally:
        new_df = pd.DataFrame(all_records)
        previous_df = load_previous_data('data.csv')
        result_df = compare_and_mark(new_df, previous_df)
        save_data(result_df)

if __name__ == '__main__':
    main()